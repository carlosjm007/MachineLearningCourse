---
title: "Practical Machine Learning"
author: "Carlos Jos√© Manosalva"
date: "September 30, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## This document has been written to complete the machine learning course.

We are going to load the data from "http://groupware.les.inf.puc-rio.br/har" they offered this information about personal activity taken from his devices; in this case, the data comes from people who made barbell lifts correctly and incorrectly in 5 different ways.

Our target is to predict the manner in which they did the exercise.

First of all, We are going to define the librarys and load the data:
```{r, results='hide',message=FALSE}
library(caret)
library(rpart)

training <- read.csv("pml-training.csv");
testing <- read.csv("pml-testing.csv");
```

To do a good job, We will clean data from the variables where exist more than 50% na records and we will delete columns where we'll cannot find variability through the rows.
```{r, results='hide'}
i_nzv <- nearZeroVar(training, saveMetrics=TRUE)
training <- training[, !i_nzv$nzv]

i_nrows <- nrow(training)
i_names_columns <- c()
i_dataRmNA <- c()
for(i in names(training)){
	if (i != "classe"){
			dataRmNA <- sum(is.na(training[,c(i)]));
			if (!(dataRmNA > (i_nrows*0.5))){
				i_names_columns <- c(i_names_columns, i);
			}
	}
}

training <- training[, c(i_names_columns,"classe")]
testing <- testing[, i_names_columns]
```

To do tests, We are going to split the data:
```{r, results='hide'}
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)

i_training <- training[inTrain,]
i_testing <- training[-inTrain,]
```

We are going to use the decision tree algorithm in our model:
```{r, results='hide'}
set.seed(2233)

modelFit <- rpart(classe ~ ., data=i_training, method="class")
```
```{r, echo=FALSE}
modelFit
```

As you can see, I have made a terrible mistake, the decision tree only uses the X column because is an enumeration of the rows, we have to delete that column.
```{r, results='hide'}
i_training$X = NULL;
```

So we are going to train again and prove the model.
```{r, results='hide'}
modelFit <- train(classe ~., data=i_training, method = "svmLinear");

i_testing$classtesting <- predict(modelFit, newdata = i_testing)
```
```{r, echo=FALSE}
confusionMatrix(i_testing$classtesting, i_testing$classe)
```

With the confusionMatrix we can see this is a good model.

Now we'll use the test data to predict the manner in which they did the exercise.
```{r, results='hide'}
testing$testpre <- predict(modelFit, newdata = testing)
for(i in 1:length(testing$testpre)){
	filename = paste0("case_",i,".txt")
	write.table(testing$testpre[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
```
```{r, echo=FALSE}
testing$testpre
```

# Conclusion
The first prediction model, when the data was splitted to train the decision tree, we didn't discriminate the X column, this can show good results when the same data are predicted, but it is not usefull with other data.